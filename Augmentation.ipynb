{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7587737,"sourceType":"datasetVersion","datasetId":4416532}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-08T09:56:26.109662Z","iopub.execute_input":"2024-02-08T09:56:26.110631Z","iopub.status.idle":"2024-02-08T09:56:26.476722Z","shell.execute_reply.started":"2024-02-08T09:56:26.110571Z","shell.execute_reply":"2024-02-08T09:56:26.475631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/clean-data/cleandata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:56:26.47837Z","iopub.execute_input":"2024-02-08T09:56:26.478789Z","iopub.status.idle":"2024-02-08T09:56:27.728345Z","shell.execute_reply.started":"2024-02-08T09:56:26.478744Z","shell.execute_reply":"2024-02-08T09:56:27.727496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:58:50.12728Z","iopub.execute_input":"2024-02-08T09:58:50.12823Z","iopub.status.idle":"2024-02-08T09:58:50.178432Z","shell.execute_reply.started":"2024-02-08T09:58:50.128192Z","shell.execute_reply":"2024-02-08T09:58:50.177531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom nltk.corpus import wordnet\nfrom random import choice, sample\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:16:44.476329Z","iopub.execute_input":"2024-02-08T10:16:44.476915Z","iopub.status.idle":"2024-02-08T10:16:45.788262Z","shell.execute_reply.started":"2024-02-08T10:16:44.476882Z","shell.execute_reply":"2024-02-08T10:16:45.787387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('averaged_perceptron_tagger')\nnltk.download('wordnet')\nnltk.download('omw-1.4')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:17:34.135709Z","iopub.execute_input":"2024-02-08T10:17:34.136212Z","iopub.status.idle":"2024-02-08T10:17:34.519348Z","shell.execute_reply.started":"2024-02-08T10:17:34.136182Z","shell.execute_reply":"2024-02-08T10:17:34.518457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_wordnet_pos(treebank_tag):\n    \"\"\"Converts treebank tags to wordnet tags.\"\"\"\n    if treebank_tag.startswith('J'):\n        return wordnet.ADJ\n    elif treebank_tag.startswith('V'):\n        return wordnet.VERB\n    elif treebank_tag.startswith('N'):\n        return wordnet.NOUN\n    elif treebank_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return None\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:18:08.407176Z","iopub.execute_input":"2024-02-08T10:18:08.407522Z","iopub.status.idle":"2024-02-08T10:18:08.414106Z","shell.execute_reply.started":"2024-02-08T10:18:08.407494Z","shell.execute_reply":"2024-02-08T10:18:08.413085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def synonym_replacement(sentence, num_replacements=2):\n    \"\"\"Performs synonym replacement on a sentence.\"\"\"\n    words = nltk.word_tokenize(sentence)\n    tagged_words = nltk.pos_tag(words)\n    \n    replaceable_words = [word for word, tag in tagged_words if get_wordnet_pos(tag) is not None]\n\n    replaced = 0\n    for word in replaceable_words:\n        synonyms = set()\n        for syn in wordnet.synsets(word, pos=get_wordnet_pos(nltk.pos_tag([word])[0][1])):\n            for lemma in syn.lemmas():\n                synonyms.add(lemma.name())\n        if word in synonyms:\n            synonyms.remove(word)\n        synonyms = list(synonyms)\n        \n        if synonyms:\n            synonym = choice(synonyms).replace('_', ' ')\n            sentence = sentence.replace(word, synonym, 1)\n            replaced += 1\n            if replaced >= num_replacements:\n                break\n    \n    return sentence","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:18:08.631751Z","iopub.execute_input":"2024-02-08T10:18:08.632145Z","iopub.status.idle":"2024-02-08T10:18:08.640858Z","shell.execute_reply.started":"2024-02-08T10:18:08.632117Z","shell.execute_reply":"2024-02-08T10:18:08.639729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\n\nnltk.download('wordnet')\nnltk.download('omw-1.4')\nnltk.download('averaged_perceptron_tagger')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:20:06.048835Z","iopub.execute_input":"2024-02-08T10:20:06.049422Z","iopub.status.idle":"2024-02-08T10:20:06.107939Z","shell.execute_reply.started":"2024-02-08T10:20:06.049392Z","shell.execute_reply":"2024-02-08T10:20:06.10706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:21:32.166253Z","iopub.execute_input":"2024-02-08T10:21:32.16663Z","iopub.status.idle":"2024-02-08T10:21:33.469425Z","shell.execute_reply.started":"2024-02-08T10:21:32.1666Z","shell.execute_reply":"2024-02-08T10:21:33.46832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# file_path = '/path/to/your/dataset.csv'  # Change this to your actual file path\n# data = pd.read_csv(file_path)\n\n# Prepare dataset for augmentation\nclass_columns = [col for col in df.columns if col != 'Text']\ndf['sum_classes'] = df[class_columns].sum(axis=1)\ntexts_with_classes = df[df['sum_classes'] > 0]\n\n# Augment texts\nnum_texts_to_augment = 5  # Change as needed\naugmented_texts = []\n\ntexts_to_augment = texts_with_classes.sample(n=min(num_texts_to_augment, len(texts_with_classes)))\n\nfor _, row in tqdm(texts_to_augment.iterrows(), total=texts_to_augment.shape[0], desc=\"Augmenting Texts\"):\n    original_text = row['Text']\n    augmented_text = synonym_replacement(original_text, num_replacements=2)  # Adjust num_replacements as needed\n    augmented_texts.append((original_text, augmented_text))\n\n# Display original and augmented texts\nfor original, augmented in augmented_texts:\n    print(f\"Original: {original}\\nAugmented: {augmented}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:21:35.813249Z","iopub.execute_input":"2024-02-08T10:21:35.813663Z","iopub.status.idle":"2024-02-08T10:21:38.025568Z","shell.execute_reply.started":"2024-02-08T10:21:35.813628Z","shell.execute_reply":"2024-02-08T10:21:38.02464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
