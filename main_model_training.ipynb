{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7497287,"sourceType":"datasetVersion","datasetId":4365552},{"sourceId":7554287,"sourceType":"datasetVersion","datasetId":4399782},{"sourceId":7559219,"sourceType":"datasetVersion","datasetId":4399713}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/soumyadeepsarkar12/infer-umiam?scriptVersionId=162365517\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-06T13:30:20.469303Z","iopub.execute_input":"2024-02-06T13:30:20.469893Z","iopub.status.idle":"2024-02-06T13:30:21.622636Z","shell.execute_reply.started":"2024-02-06T13:30:20.469862Z","shell.execute_reply":"2024-02-06T13:30:21.621756Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/hehehe/cleandata.csv\n/kaggle/input/kriti-24/sample_submission.csv\n/kaggle/input/kriti-24/train.csv\n/kaggle/input/kriti-24/test.csv\n/kaggle/input/hello1/model1.pth\n/kaggle/input/hello1/model2.pth\n/kaggle/input/hello1/model4.pth\n/kaggle/input/hello1/model5.pth\n/kaggle/input/hello1/state.db\n/kaggle/input/hello1/submission.csv\n/kaggle/input/hello1/submission_ordered_new.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nimport os\nimport torch\nimport re\nimport string\nimport json\n\nimport emoji\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nfrom bs4 import BeautifulSoup\nimport torch.nn as nn\nimport transformers\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n","metadata":{"execution":{"iopub.status.busy":"2024-02-06T13:30:21.62487Z","iopub.execute_input":"2024-02-06T13:30:21.625728Z","iopub.status.idle":"2024-02-06T13:30:31.592644Z","shell.execute_reply.started":"2024-02-06T13:30:21.625672Z","shell.execute_reply":"2024-02-06T13:30:31.591572Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/hehehe/cleandata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-06T13:30:31.59437Z","iopub.execute_input":"2024-02-06T13:30:31.595137Z","iopub.status.idle":"2024-02-06T13:30:33.117783Z","shell.execute_reply.started":"2024-02-06T13:30:31.595094Z","shell.execute_reply":"2024-02-06T13:30:33.116513Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-02-06T13:30:33.119111Z","iopub.execute_input":"2024-02-06T13:30:33.119527Z","iopub.status.idle":"2024-02-06T13:30:33.173747Z","shell.execute_reply.started":"2024-02-06T13:30:33.119495Z","shell.execute_reply":"2024-02-06T13:30:33.172487Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                    Text  q-bio.GN  stat.AP  \\\n0      axiomatic aspects default inference paper stud...         0        0   \n1      extensions group infinite conjugacy classes ch...         0        0   \n2      complexvalued cnns rf datadriven wireless devi...         0        0   \n3      reconstruction drift diffusion transition prob...         0        0   \n4      three classes propagation rules grs egrs codes...         0        0   \n...                                                  ...       ...      ...   \n51205  generalized fourier integral operators spaces ...         0        0   \n51206  weaklysupervised 3d visual grounding visual li...         0        0   \n51207  strongly pseudoconvex handlebodies explicit co...         0        0   \n51208  improving endtoend speech processing efficient...         0        0   \n51209  second class particles microscopic characteris...         0        0   \n\n       q-fin.TR  math.GR  q-bio.NC  math.NT  q-fin.MF  cs.SE  math.LO  ...  \\\n0             0        0         0        0         0      0        0  ...   \n1             0        1         0        0         0      0        0  ...   \n2             0        0         0        0         0      0        0  ...   \n3             0        0         0        0         0      0        0  ...   \n4             0        0         0        0         0      0        0  ...   \n...         ...      ...       ...      ...       ...    ...      ...  ...   \n51205         0        0         0        0         0      0        0  ...   \n51206         0        0         0        0         0      0        0  ...   \n51207         0        0         0        0         0      0        0  ...   \n51208         0        0         0        0         0      0        0  ...   \n51209         0        0         0        0         0      0        0  ...   \n\n       cs.CL  econ.GN  q-fin.GN  math.ST  econ.TH  math.QA  math.IT  stat.TH  \\\n0          0        0         0        0        0        0        0        0   \n1          0        0         0        0        0        0        0        0   \n2          0        0         0        0        0        0        1        0   \n3          0        0         0        1        0        0        0        1   \n4          0        0         0        0        0        0        1        0   \n...      ...      ...       ...      ...      ...      ...      ...      ...   \n51205      0        0         0        0        0        0        0        0   \n51206      1        0         0        0        0        0        0        0   \n51207      0        0         0        0        0        0        0        0   \n51208      1        0         0        0        0        0        0        0   \n51209      0        0         0        0        0        0        0        0   \n\n       math.CO  q-fin.RM  \n0            0         0  \n1            0         0  \n2            0         0  \n3            0         0  \n4            0         0  \n...        ...       ...  \n51205        0         0  \n51206        0         0  \n51207        0         0  \n51208        0         0  \n51209        0         0  \n\n[51210 rows x 58 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>q-bio.GN</th>\n      <th>stat.AP</th>\n      <th>q-fin.TR</th>\n      <th>math.GR</th>\n      <th>q-bio.NC</th>\n      <th>math.NT</th>\n      <th>q-fin.MF</th>\n      <th>cs.SE</th>\n      <th>math.LO</th>\n      <th>...</th>\n      <th>cs.CL</th>\n      <th>econ.GN</th>\n      <th>q-fin.GN</th>\n      <th>math.ST</th>\n      <th>econ.TH</th>\n      <th>math.QA</th>\n      <th>math.IT</th>\n      <th>stat.TH</th>\n      <th>math.CO</th>\n      <th>q-fin.RM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>axiomatic aspects default inference paper stud...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>extensions group infinite conjugacy classes ch...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>complexvalued cnns rf datadriven wireless devi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>reconstruction drift diffusion transition prob...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>three classes propagation rules grs egrs codes...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51205</th>\n      <td>generalized fourier integral operators spaces ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51206</th>\n      <td>weaklysupervised 3d visual grounding visual li...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51207</th>\n      <td>strongly pseudoconvex handlebodies explicit co...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51208</th>\n      <td>improving endtoend speech processing efficient...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51209</th>\n      <td>second class particles microscopic characteris...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>51210 rows Ã— 58 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-06T13:30:33.176086Z","iopub.execute_input":"2024-02-06T13:30:33.176455Z","iopub.status.idle":"2024-02-06T13:30:33.219529Z","shell.execute_reply.started":"2024-02-06T13:30:33.176423Z","shell.execute_reply":"2024-02-06T13:30:33.218273Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 51210 entries, 0 to 51209\nData columns (total 58 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   Text      51210 non-null  object\n 1   q-bio.GN  51210 non-null  int64 \n 2   stat.AP   51210 non-null  int64 \n 3   q-fin.TR  51210 non-null  int64 \n 4   math.GR   51210 non-null  int64 \n 5   q-bio.NC  51210 non-null  int64 \n 6   math.NT   51210 non-null  int64 \n 7   q-fin.MF  51210 non-null  int64 \n 8   cs.SE     51210 non-null  int64 \n 9   math.LO   51210 non-null  int64 \n 10  econ.EM   51210 non-null  int64 \n 11  q-fin.PM  51210 non-null  int64 \n 12  cs.CE     51210 non-null  int64 \n 13  q-bio.MN  51210 non-null  int64 \n 14  cs.CV     51210 non-null  int64 \n 15  math.PR   51210 non-null  int64 \n 16  eess.SP   51210 non-null  int64 \n 17  math.AT   51210 non-null  int64 \n 18  cs.SD     51210 non-null  int64 \n 19  stat.CO   51210 non-null  int64 \n 20  q-fin.EC  51210 non-null  int64 \n 21  cs.OS     51210 non-null  int64 \n 22  q-fin.CP  51210 non-null  int64 \n 23  q-bio.CB  51210 non-null  int64 \n 24  cs.DC     51210 non-null  int64 \n 25  eess.IV   51210 non-null  int64 \n 26  q-bio.BM  51210 non-null  int64 \n 27  math.CV   51210 non-null  int64 \n 28  stat.ML   51210 non-null  int64 \n 29  eess.AS   51210 non-null  int64 \n 30  stat.ME   51210 non-null  int64 \n 31  cs.LO     51210 non-null  int64 \n 32  cs.DM     51210 non-null  int64 \n 33  cs.GT     51210 non-null  int64 \n 34  cs.RO     51210 non-null  int64 \n 35  cs.IR     51210 non-null  int64 \n 36  cs.PL     51210 non-null  int64 \n 37  cs.CR     51210 non-null  int64 \n 38  math.AC   51210 non-null  int64 \n 39  cs.IT     51210 non-null  int64 \n 40  cs.AR     51210 non-null  int64 \n 41  cs.AI     51210 non-null  int64 \n 42  q-bio.TO  51210 non-null  int64 \n 43  cs.LG     51210 non-null  int64 \n 44  q-fin.PR  51210 non-null  int64 \n 45  math.AP   51210 non-null  int64 \n 46  cs.NI     51210 non-null  int64 \n 47  cs.DB     51210 non-null  int64 \n 48  cs.CL     51210 non-null  int64 \n 49  econ.GN   51210 non-null  int64 \n 50  q-fin.GN  51210 non-null  int64 \n 51  math.ST   51210 non-null  int64 \n 52  econ.TH   51210 non-null  int64 \n 53  math.QA   51210 non-null  int64 \n 54  math.IT   51210 non-null  int64 \n 55  stat.TH   51210 non-null  int64 \n 56  math.CO   51210 non-null  int64 \n 57  q-fin.RM  51210 non-null  int64 \ndtypes: int64(57), object(1)\nmemory usage: 22.7+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Specify the list of columns you want to check for 1s\ncolumns_to_check = ['q-bio.GN', 'q-fin.TR', 'q-bio.NC', 'q-fin.MF', 'q-fin.PM', 'cs.CE', 'q-bio.MN', 'math.AT',\n                    'stat.CO', 'q-fin.EC', 'cs.OS', 'q-fin.CP', 'q-bio.CB', 'q-bio.BM', 'cs.DM', 'cs.GT', 'cs.AR',\n                    'q-bio.TO', 'q-fin.PR', 'econ.GN', 'q-fin.GN', 'econ.TH', 'q-fin.RM']\n\n# Create a mask to identify rows where at least one of the specified columns has a value of 1\nmask = df[columns_to_check].any(axis=1)\n\n# Filter the DataFrame to keep only the rows where the mask is True\nfiltered_df = df[mask]\n\n# If you want to drop the original columns that were checked, you can use:\n# filtered_df = filtered_df.drop(columns=columns_to_check)\n\n# Now, filtered_df contains only the rows where at least one of the specified columns has a value of 1\nprint(filtered_df)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_df.reset_index(drop=True, inplace=True)\n\n# The 'drop=True' argument will drop the old index, and 'inplace=True' will modify the DataFrame in place.\n\n# Now, the filtered_df has a reset index starting from 0.\nprint(filtered_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Calculate the frequency of each class\nclass_frequencies = filtered_df.iloc[:, 1:-1].sum().sort_values(ascending=False)\n\n# Plot class frequencies\nplt.figure(figsize=(12, 8))\nclass_frequencies.plot(kind='bar')\nplt.title('Frequency of Each Class')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.xticks(rotation=90)\nplt.show()\n\nclass_frequencies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming `df` is your DataFrame and `columns_to_check` is your list of columns\n# Create a mask to identify rows where all specified columns do not have a value of 1\nmask = df[columns_to_check].sum(axis=1) == 0\n\n# Use the mask to filter the DataFrame\ndf_majority = df[mask]\n\n# Now `df_filtered` contains rows where none of the specified columns have a value of 1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_majority.reset_index(drop=True, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_majority","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the frequency of each class\nclass_frequencies = df_majority.iloc[:, 1:-1].sum().sort_values(ascending=False)\n\n# Plot class frequencies\nplt.figure(figsize=(12, 8))\nclass_frequencies.plot(kind='bar')\nplt.title('Frequency of Each Class')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.xticks(rotation=90)\nplt.show()\n\nclass_frequencies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols = [col for col in df.columns if col not in ['Text']]\nlen(target_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 200\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 32\nEPOCHS = 10\nLEARNING_RATE = 3e-9\ntokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class BERTDataset(Dataset):\n#     def __init__(self, df, tokenizer, max_len):\n#         self.df = df\n#         self.max_len = max_len\n#         self.text = df.Text\n#         self.tokenizer = tokenizer\n#         self.targets = df[target_cols].values\n        \n#     def __len__(self):\n#         return len(self.df)\n    \n#     def __getitem__(self, index):\n#         text = self.text[index]\n#         inputs = self.tokenizer.encode_plus(\n#             text,\n#             truncation=True,\n#             add_special_tokens=True,\n#             max_length=self.max_len,\n#             padding='max_length',\n#             return_token_type_ids=True\n#         )\n#         ids = inputs['input_ids']\n#         mask = inputs['attention_mask']\n#         token_type_ids = inputs[\"token_type_ids\"]\n        \n#         return {\n#             'ids': torch.tensor(ids, dtype=torch.long),\n#             'mask': torch.tensor(mask, dtype=torch.long),\n#             'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n#             'targets': torch.tensor(self.targets[index], dtype=torch.float)\n#         }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_dataset_minor = BERTDataset(df, tokenizer, MAX_LEN)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# majority = DataLoader(train_dataset_minor, batch_size=TRAIN_BATCH_SIZE, \n#                           num_workers=4, shuffle=True, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import pandas as pd\n# from torch.utils.data import Dataset, DataLoader\n# from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n# from sklearn.metrics import accuracy_score, f1_score\n# from sklearn.model_selection import train_test_split\n# from transformers import AutoModel\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class MultiLabelSciBERT(torch.nn.Module):\n#     def __init__(self, num_labels):\n#         super(MultiLabelSciBERT, self).__init__()\n#         self.sci_bert = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n#         self.classifier = torch.nn.Linear(768, num_labels)\n\n#     def forward(self, ids,mask):\n#         outputs = self.sci_bert(ids, attention_mask=mask)\n#         sequence_output = outputs[0][:, 0, :]  \n#         return self.classifier(sequence_output)\n    \n    \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FROM HERE FOR INFERENCE","metadata":{}},{"cell_type":"code","source":"model_news= MultiLabelSciBERT(57)\nmodel_path = '/kaggle/input/hello1/model5.pth'\nloaded_st = torch.load(model_path)\nmodel_news.load_state_dict(loaded_st)\nmodel_news.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def validation():\n#     model_news.eval() \n#     fin_targets=[]\n#     fin_outputs=[]\n#     with torch.no_grad():\n#         for _, data in enumerate(majority, 0):\n#             ids = data['ids'].to(device, dtype = torch.long)\n#             mask = data['mask'].to(device, dtype = torch.long)\n#             token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n#             targets = data['targets'].to(device, dtype = torch.float)\n#             outputs = model_news(ids, mask)\n# #              outputs = model(ids, mask)\n#             fin_targets.extend(targets.cpu().detach().numpy().tolist())\n#             fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n#     return fin_outputs, fin_targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# from torch.cuda.amp import autocast\n# import torch\n# from torch.cuda.amp import GradScaler\n\n# # Define the GradScaler object\n# scaler = GradScaler()\n# def train(epoch):\n#     model_news.train()\n#     for _, data in enumerate(majority, 0):\n#         ids = data['ids'].to(device, dtype=torch.long)\n#         mask = data['mask'].to(device, dtype=torch.long)\n#         targets = data['targets'].to(device, dtype=torch.float)\n\n#         optimizer.zero_grad()\n\n#         with autocast():\n#             outputs = model_news(ids, mask)\n#             loss = loss_fn(outputs, targets )\n\n#         scaler.scale(loss).backward()\n#         scaler.step(optimizer)\n#         scaler.update()\n\n#         if _ % 500 == 0:\n#             print(f'Epoch: {epoch}, Loss: {loss.item()}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim import AdamW\noptimizer = AdamW(model_news.parameters(), lr=LEARNING_RATE, weight_decay=1e-6)\n\ndef loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for epoch in range(EPOCHS):\n#     train(epoch) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def validation():\n#     model_news.eval() \n#     fin_targets=[]\n#     fin_outputs=[]\n#     with torch.no_grad():\n#         for _, data in enumerate(majority, 0):\n#             ids = data['ids'].to(device, dtype = torch.long)\n#             mask = data['mask'].to(device, dtype = torch.long)\n#             token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n#             targets = data['targets'].to(device, dtype = torch.float)\n#             outputs = model_news(ids, mask)\n# #              outputs = model(ids, mask)\n#             fin_targets.extend(targets.cpu().detach().numpy().tolist())\n#             fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n#     return fin_outputs, fin_targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# outputs, targets = validation()\n# outputs = np.array(outputs) >= 0.5\n# accuracy = metrics.accuracy_score(targets, outputs)\n# f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n# f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n# print(f\"Accuracy Score = {accuracy}\")\n# print(f\"F1 Score (Micro) = {f1_score_micro}\")\n# print(f\"F1 Score (Macro) = {f1_score_macro}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING ON MINORITY CLASSES ","metadata":{}},{"cell_type":"code","source":"# import torch\n# from torch.cuda.amp import autocast\n# import torch\n# from torch.cuda.amp import GradScaler\n\n# # Define the GradScaler object\n# scaler = GradScaler()\n# def train(epoch):\n#     model.train()\n#     for _, data in enumerate(train_loader, 0):\n#         ids = data['ids'].to(device, dtype=torch.long)\n#         mask = data['mask'].to(device, dtype=torch.long)\n#         targets = data['targets'].to(device, dtype=torch.float)\n\n#         optimizer.zero_grad()\n\n#         with autocast():\n#             outputs = model(ids, mask)\n#             loss = loss_fn(outputs, targets )\n\n#         scaler.scale(loss).backward()\n#         scaler.step(optimizer)\n#         scaler.update()\n\n#         if _ % 500 == 0:\n#             print(f'Epoch: {epoch}, Loss: {loss.item()}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RUNNING ON TEST SET","metadata":{}},{"cell_type":"code","source":"def predict():\n    model_news.eval()\n    predictions = []\n    with torch.no_grad():\n        for _, data in enumerate(majority, 0):\n            ids = data['ids'].to(device, dtype=torch.long)\n            mask = data['mask'].to(device, dtype=torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n\n            outputs = model_news(ids, mask)\n            predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return predictions\n\n# Get predictions\ntest_predictions = predict()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv=pd.read_csv('/kaggle/input/kriti-24/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming you have two DataFrames: df and train_csv\n# Add the 'Id' column from train_csv to df\ndf['Id'] = train_csv['Id']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Convert predictions to binary (True/False)\nbinary_predictions = np.array(test_predictions) >= 0.5\n\n# Convert boolean values to integers (1/0)\nbinary_predictions_int = binary_predictions.astype(int)\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame(binary_predictions_int, columns=target_cols)\nsubmission_df.insert(0, 'Text', df.Text)\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols2 = [col for col in df.columns if col not in ['Text','Title','Abstract','Id']]\nlen(target_cols2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Convert predictions to binary (True/False)\nbinary_predictions = np.array(test_predictions) >= 0.5\n\n# Convert boolean values to integers (1/0)\nbinary_predictions_int = binary_predictions.astype(int)\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame(binary_predictions_int, columns=target_cols2)\nsubmission_df.insert(0, 'Id', df.Id)\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template_df = pd.read_csv('/kaggle/input/kriti-24/sample_submission.csv')\nrequired_column_order = template_df.columns.tolist()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Ensure that 'Id' is the first column\n# required_column_order.remove('Id')\n# required_column_order.insert(0, 'Id')\n\n# Reorder your DataFrame columns\ntrain_predict = submission_df[required_column_order]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predict.loc[:, 'Text'] = df['Text'].copy()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predict.drop(['Id'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_column = train_predict.pop(train_predict.columns[-1])\ntrain_predict.insert(0, last_column.name, last_column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predict\nsave","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DOING A PREDICTION ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n# Load the test dataset\ntest_df = pd.read_csv(\"/kaggle/input/kriti-24/test.csv\")\n\n# Preprocess the text data\ntest_df['Text'] = test_df['Title'] + ' ' + test_df['Abstract']\ntest_df = test_df.drop(['Title', 'Abstract'], axis=1)\ntest_df['Text']=test_df['Text'].str.lower()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_punct(text):\n    punctuation =string.punctuation\n    return text.translate(str.maketrans('' , '',punctuation))\ntest_df['Text']=test_df['Text'].apply(lambda x: remove_punct(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords \n\",\".join(stopwords.words('english'))\nSTOPWRDS=set(stopwords.words('english'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_stp(Text):\n    return \" \".join([word for word in Text.split() if word not in STOPWRDS])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Text']=test_df['Text'].apply(lambda x: remove_stp(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_needed = [\n     \"using\", \"results\", \"performance\", \"show\", \"method\", \"approach\",\n    \"also\", \"based\", \"problem\", \"proposed\", \"two\", \"information\", \"new\", \"large\",\n    \"different\", \"study\", \"however\",  \"analysis\", \"one\", \"work\", \"used\", \"first\",\n    \"set\", \"use\", \"existing\", \"present\", \"process\", \"demonstrate\", \"task\", \"general\",\n    \"several\", \"due\", \"compared\", \"via\", \"moreover\", \"eg\", \"thus\", \"possible\", \"make\",\n    \"like\", \"important\", \"key\", \"furthermore\", \"give\", \"state\", \"certain\", \"ie\", \"form\",\n    \"allows\", \"finally\", \"often\", \"even\", \"many\", \"various\", \"well\", \"also\", \"however\",\n    \"several\", \"due\", \"across\", \"may\", \"without\", \"among\", \"including\", \"particular\",\n    \"especially\", \"either\", \"often\", \"even\", \"moreover\", \"thus\", \"ie\", \"eg\", \"although\",\n    \"despite\",\"would\" ,\"within\" ,\"\",\n]\n\nimport pandas as pd\ndef not_need(Text):\n    return \" \".join([word for word in Text.split() if word not in not_needed])\n\ntest_df['Text'] = test_df['Text'].apply(lambda x:not_need(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTTestDatasets(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.text = df.Text\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n        }\n\n# Create the test dataset\nresult_dataset = BERTTestDatasets(test_df, tokenizer, MAX_LEN)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_loader = DataLoader(result_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=4)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict():\n    model_news.eval()\n    predictions = []\n    with torch.no_grad():\n        for _, data in enumerate(result_loader, 0):\n            ids = data['ids'].to(device, dtype=torch.long)\n            mask = data['mask'].to(device, dtype=torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n\n            outputs = model_news(ids, mask)\n            predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return predictions\n\n# Get predictions\ntest_predictions = predict()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Convert predictions to binary (True/False)\nbinary_predictions = np.array(test_predictions) >= 0.5\n\n# Convert boolean values to integers (1/0)\nbinary_predictions_int = binary_predictions.astype(int)\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame(binary_predictions_int, columns=target_cols)\nsubmission_df.insert(0, 'Id', test_df.Id)\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols2 = [col for col in df.columns if col not in ['Text','Title','Abstract']]\nlen(target_cols2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Convert predictions to binary (True/False)\nbinary_predictions = np.array(test_predictions) >= 0.5\n\n# Convert boolean values to integers (1/0)\nbinary_predictions_int = binary_predictions.astype(int)\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame(binary_predictions_int, columns=target_cols2)\nsubmission_df.insert(0, 'Id', test_df.Id)\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template_df = pd.read_csv('/kaggle/input/kriti-24/sample_submission.csv')\nrequired_column_order = template_df.columns.tolist()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensure that 'Id' is the first column\nrequired_column_order.remove('Id')\nrequired_column_order.insert(0, 'Id')\n\n# Reorder your DataFrame columns\nsubmission_df = submission_df[required_column_order]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION_ORDER_NEW is the main submission file","metadata":{}},{"cell_type":"code","source":"submission_df\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
