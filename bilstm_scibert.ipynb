{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7596810,"sourceType":"datasetVersion","datasetId":4421990},{"sourceId":7596822,"sourceType":"datasetVersion","datasetId":4421998},{"sourceId":7597248,"sourceType":"datasetVersion","datasetId":4422289}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-09T16:34:41.525034Z","iopub.execute_input":"2024-02-09T16:34:41.525877Z","iopub.status.idle":"2024-02-09T16:34:41.537373Z","shell.execute_reply.started":"2024-02-09T16:34:41.525845Z","shell.execute_reply":"2024-02-09T16:34:41.536341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nimport os\nimport torch\nimport re\nimport string\nimport json\n\nimport emoji\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nfrom bs4 import BeautifulSoup\nimport torch.nn as nn\nimport transformers\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:34:41.734551Z","iopub.execute_input":"2024-02-09T16:34:41.734835Z","iopub.status.idle":"2024-02-09T16:34:41.741688Z","shell.execute_reply.started":"2024-02-09T16:34:41.734811Z","shell.execute_reply":"2024-02-09T16:34:41.74069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoModel\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:34:41.972879Z","iopub.execute_input":"2024-02-09T16:34:41.973165Z","iopub.status.idle":"2024-02-09T16:34:41.97809Z","shell.execute_reply.started":"2024-02-09T16:34:41.973141Z","shell.execute_reply":"2024-02-09T16:34:41.97706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nfrom itertools import combinations\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:34:42.169921Z","iopub.execute_input":"2024-02-09T16:34:42.170218Z","iopub.status.idle":"2024-02-09T16:34:42.174943Z","shell.execute_reply.started":"2024-02-09T16:34:42.170185Z","shell.execute_reply":"2024-02-09T16:34:42.174017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/clean-data/cleandata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:34:42.389866Z","iopub.execute_input":"2024-02-09T16:34:42.390316Z","iopub.status.idle":"2024-02-09T16:34:43.041761Z","shell.execute_reply.started":"2024-02-09T16:34:42.390288Z","shell.execute_reply":"2024-02-09T16:34:43.04098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train,df_test = train_test_split(df, test_size=0.15, random_state=42)\n\ndf_train = df_train.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:34:44.450718Z","iopub.execute_input":"2024-02-09T16:34:44.451418Z","iopub.status.idle":"2024-02-09T16:34:44.503728Z","shell.execute_reply.started":"2024-02-09T16:34:44.451387Z","shell.execute_reply":"2024-02-09T16:34:44.502913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:34:45.49339Z","iopub.execute_input":"2024-02-09T16:34:45.494141Z","iopub.status.idle":"2024-02-09T16:34:45.547419Z","shell.execute_reply.started":"2024-02-09T16:34:45.494111Z","shell.execute_reply":"2024-02-09T16:34:45.546424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 256\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 16\nEPOCHS = 10\nLEARNING_RATE = 4e-7\ntokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:34:46.857113Z","iopub.execute_input":"2024-02-09T16:34:46.857924Z","iopub.status.idle":"2024-02-09T16:34:47.639447Z","shell.execute_reply.started":"2024-02-09T16:34:46.857896Z","shell.execute_reply":"2024-02-09T16:34:47.63862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.text = df.Text\n        self.tokenizer = tokenizer\n        self.targets = df[target_cols].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:10:02.615994Z","iopub.execute_input":"2024-02-09T18:10:02.616449Z","iopub.status.idle":"2024-02-09T18:10:02.626287Z","shell.execute_reply.started":"2024-02-09T18:10:02.616415Z","shell.execute_reply":"2024-02-09T18:10:02.625331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols = [col for col in df.columns if col not in ['Text','Title','Abstract']]\nlen(target_cols)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:10:02.627779Z","iopub.execute_input":"2024-02-09T18:10:02.628046Z","iopub.status.idle":"2024-02-09T18:10:02.650922Z","shell.execute_reply.started":"2024-02-09T18:10:02.628024Z","shell.execute_reply":"2024-02-09T18:10:02.650022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = BERTDataset(df_train, tokenizer, MAX_LEN)\ntest_dataset = BERTDataset(df_test, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:10:02.651842Z","iopub.execute_input":"2024-02-09T18:10:02.652634Z","iopub.status.idle":"2024-02-09T18:10:02.680041Z","shell.execute_reply.started":"2024-02-09T18:10:02.652609Z","shell.execute_reply":"2024-02-09T18:10:02.679319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, \n                          num_workers=4, shuffle=True, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=VALID_BATCH_SIZE, \n                          num_workers=4, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:10:02.787997Z","iopub.execute_input":"2024-02-09T18:10:02.788901Z","iopub.status.idle":"2024-02-09T18:10:02.793932Z","shell.execute_reply.started":"2024-02-09T18:10:02.788865Z","shell.execute_reply":"2024-02-09T18:10:02.792918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel\nfrom torch.cuda.amp import autocast, GradScaler\n\nclass MultiLabelSciBERT(nn.Module):\n    def __init__(self, num_labels, hidden_dim=768, lstm_hidden=384, num_layers=2, bidirectional=True):\n        super(MultiLabelSciBERT, self).__init__()\n        self.sci_bert = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n\n        # Optionally, freeze SciBERT parameters\n        for param in self.sci_bert.parameters():\n            param.requires_grad = False\n\n        self.bilstm = nn.LSTM(input_size=hidden_dim, \n                              hidden_size=lstm_hidden, \n                              num_layers=num_layers, \n                              bidirectional=bidirectional, \n                              batch_first=True)\n        \n        lstm_output_features = lstm_hidden * 2 if bidirectional else lstm_hidden\n        self.classifier = nn.Linear(lstm_output_features, num_labels)\n\n    def forward(self, ids, mask):\n        outputs = self.sci_bert(ids, attention_mask=mask)\n        sequence_output = outputs[0]\n        \n        lstm_output, _ = self.bilstm(sequence_output)\n        pooled_output = lstm_output[:, 0, :]  # Use the output of the first token for classification\n        \n        logits = self.classifier(pooled_output)\n        return logits\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:16:09.612115Z","iopub.execute_input":"2024-02-09T18:16:09.612532Z","iopub.status.idle":"2024-02-09T18:16:09.62289Z","shell.execute_reply.started":"2024-02-09T18:16:09.612497Z","shell.execute_reply":"2024-02-09T18:16:09.621937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, optimizer, loss_function, device, epoch, scaler):\n    model.train()\n    for _, data in enumerate(train_loader, 0):\n        ids = data['ids'].to(device, dtype=torch.long)\n        mask = data['mask'].to(device, dtype=torch.long)\n        targets = data['targets'].to(device, dtype=torch.float)\n\n        optimizer.zero_grad()\n\n        with autocast():\n            logits = model(ids, mask)\n            loss = loss_function(logits, targets)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        if _ % 500 == 0:\n            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:16:10.06549Z","iopub.execute_input":"2024-02-09T18:16:10.066318Z","iopub.status.idle":"2024-02-09T18:16:10.073311Z","shell.execute_reply.started":"2024-02-09T18:16:10.066288Z","shell.execute_reply":"2024-02-09T18:16:10.07225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_labels = 57  # Update this with the actual number of labels for your task\nmodel = MultiLabelSciBERT(num_labels=num_labels).to(device)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:16:10.580562Z","iopub.execute_input":"2024-02-09T18:16:10.581301Z","iopub.status.idle":"2024-02-09T18:16:11.698714Z","shell.execute_reply.started":"2024-02-09T18:16:10.581272Z","shell.execute_reply":"2024-02-09T18:16:11.697844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Before loading custom state, check some SciBERT layer weights\nprint(\"Before loading custom checkpoint:\")\nfor name, param in model.named_parameters():\n    if 'sci_bert' in name and 'embeddings' in name:\n        print(f\"{name}: {param.mean().item()}\")\n\n# Assuming you've loaded your model as shown previously\ncustom_pretrained_state = torch.load('/kaggle/input/model-new/model5.pth', map_location=device)\nmodel.load_state_dict(custom_pretrained_state, strict=False)\n\n# After loading custom state, check the same SciBERT layer weights\nprint(\"\\nAfter loading custom checkpoint:\")\nfor name, param in model.named_parameters():\n    if 'sci_bert' in name and 'embeddings' in name:\n        print(f\"{name}: {param.mean().item()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:16:11.700301Z","iopub.execute_input":"2024-02-09T18:16:11.700592Z","iopub.status.idle":"2024-02-09T18:16:11.985295Z","shell.execute_reply.started":"2024-02-09T18:16:11.700566Z","shell.execute_reply":"2024-02-09T18:16:11.984315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DistributionBalancedLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0, beta=0.690, epsilon=1e-9, max_factor=40.0):\n        super(DistributionBalancedLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.beta = beta\n        self.epsilon = epsilon\n        self.max_factor = max_factor  # Maximum allowed value for class_balancing_factor\n\n    def forward(self, logits, targets):\n        # logits: [N, C], targets: [N, C] where N is batch size and C is number of classes\n        probs = torch.sigmoid(logits)\n        pt = probs * targets + (1 - probs) * (1 - targets)  # pt is the probability of the prediction being correct\n\n        # Class balancing factor\n        class_freq = torch.sum(targets, dim=0) / (targets.size(0) + self.epsilon)  # Added epsilon to avoid division by zero\n        class_balancing_factor = (1 - self.beta) / (1 - torch.pow(self.beta, class_freq))\n\n        # Cap the class_balancing_factor to avoid it becoming too large\n        class_balancing_factor = torch.clamp(class_balancing_factor, max=self.max_factor)\n\n        # Modulating factor\n        modulating_factor = torch.pow(1.0 - pt, self.gamma)\n\n        # Focal loss component\n        focal_loss = -self.alpha * modulating_factor * torch.log(pt + self.epsilon)\n\n        # Applying class balancing\n        balanced_focal_loss = class_balancing_factor * focal_loss\n\n        # Average over the batch\n        loss = torch.mean(torch.sum(balanced_focal_loss, dim=1))\n\n        return loss\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:16:11.986907Z","iopub.execute_input":"2024-02-09T18:16:11.98722Z","iopub.status.idle":"2024-02-09T18:16:11.997162Z","shell.execute_reply.started":"2024-02-09T18:16:11.987187Z","shell.execute_reply":"2024-02-09T18:16:11.996231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_function = DistributionBalancedLoss().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:16:12.464136Z","iopub.execute_input":"2024-02-09T18:16:12.465067Z","iopub.status.idle":"2024-02-09T18:16:12.469263Z","shell.execute_reply.started":"2024-02-09T18:16:12.465038Z","shell.execute_reply":"2024-02-09T18:16:12.468203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n\n\nscaler = GradScaler()\n\nEPOCHS = 15  # Adjust based on your needs\n# Assume train_loader is defined elsewhere\n\nfor epoch in range(EPOCHS):\n    train(model, train_loader, optimizer, loss_function, device, epoch, scaler)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:16:24.346161Z","iopub.execute_input":"2024-02-09T18:16:24.346896Z","iopub.status.idle":"2024-02-09T18:22:30.327797Z","shell.execute_reply.started":"2024-02-09T18:16:24.346858Z","shell.execute_reply":"2024-02-09T18:22:30.325986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_kriti2.pth')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validation():\n    model.eval() \n    fin_targets=[]\n    fin_outputs=[]\n    with torch.no_grad():\n        for _, data in enumerate(test_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask)\n#              outputs = model(ids, mask)\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return fin_outputs, fin_targets","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:22:34.744256Z","iopub.execute_input":"2024-02-09T18:22:34.745156Z","iopub.status.idle":"2024-02-09T18:22:34.753103Z","shell.execute_reply.started":"2024-02-09T18:22:34.745112Z","shell.execute_reply":"2024-02-09T18:22:34.752068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs, targets = validation()\noutputs = np.array(outputs) >= 0.5\naccuracy = metrics.accuracy_score(targets, outputs)\nf1_score_micro = metrics.f1_score(targets, outputs, average='micro')\nf1_score_macro = metrics.f1_score(targets, outputs, average='macro')\nprint(f\"Accuracy Score = {accuracy}\")\nprint(f\"F1 Score (Micro) = {f1_score_micro}\")\nprint(f\"F1 Score (Macro) = {f1_score_macro}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:22:34.96308Z","iopub.execute_input":"2024-02-09T18:22:34.963466Z","iopub.status.idle":"2024-02-09T18:24:43.619115Z","shell.execute_reply.started":"2024-02-09T18:22:34.963437Z","shell.execute_reply":"2024-02-09T18:24:43.618011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# Load the test dataset\ntest_df = pd.read_csv(\"/kaggle/input/kriti-csv/test.csv\")\n\n# Preprocess the text data\ntest_df['Text'] = test_df['Title'] + ' ' + test_df['Abstract']\ntest_df = test_df.drop(['Title', 'Abstract'], axis=1)\ntest_df['Text']=test_df['Text'].str.lower()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:25:04.109523Z","iopub.execute_input":"2024-02-09T18:25:04.110268Z","iopub.status.idle":"2024-02-09T18:25:04.278049Z","shell.execute_reply.started":"2024-02-09T18:25:04.110235Z","shell.execute_reply":"2024-02-09T18:25:04.277226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_punct(text):\n    punctuation =string.punctuation\n    return text.translate(str.maketrans('' , '',punctuation))\ntest_df['Text']=test_df['Text'].apply(lambda x: remove_punct(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:25:04.593088Z","iopub.execute_input":"2024-02-09T18:25:04.593724Z","iopub.status.idle":"2024-02-09T18:25:04.698324Z","shell.execute_reply.started":"2024-02-09T18:25:04.593694Z","shell.execute_reply":"2024-02-09T18:25:04.697325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords \n\",\".join(stopwords.words('english'))\nSTOPWRDS=set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:25:04.700259Z","iopub.execute_input":"2024-02-09T18:25:04.700842Z","iopub.status.idle":"2024-02-09T18:25:04.706493Z","shell.execute_reply.started":"2024-02-09T18:25:04.700809Z","shell.execute_reply":"2024-02-09T18:25:04.705527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_stp(Text):\n    return \" \".join([word for word in Text.split() if word not in STOPWRDS])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:25:04.708233Z","iopub.execute_input":"2024-02-09T18:25:04.708979Z","iopub.status.idle":"2024-02-09T18:25:04.71572Z","shell.execute_reply.started":"2024-02-09T18:25:04.708948Z","shell.execute_reply":"2024-02-09T18:25:04.71495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Text']=test_df['Text'].apply(lambda x: remove_stp(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:25:04.765321Z","iopub.execute_input":"2024-02-09T18:25:04.765563Z","iopub.status.idle":"2024-02-09T18:25:05.127942Z","shell.execute_reply.started":"2024-02-09T18:25:04.765543Z","shell.execute_reply":"2024-02-09T18:25:05.127162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_needed = [\n     \"using\", \"results\", \"performance\", \"show\", \"method\", \"approach\",\n    \"also\", \"based\", \"problem\", \"proposed\", \"two\", \"information\", \"new\", \"large\",\n    \"different\", \"study\", \"however\",  \"analysis\", \"one\", \"work\", \"used\", \"first\",\n    \"set\", \"use\", \"existing\", \"present\", \"process\", \"demonstrate\", \"task\", \"general\",\n    \"several\", \"due\", \"compared\", \"via\", \"moreover\", \"eg\", \"thus\", \"possible\", \"make\",\n    \"like\", \"important\", \"key\", \"furthermore\", \"give\", \"state\", \"certain\", \"ie\", \"form\",\n    \"allows\", \"finally\", \"often\", \"even\", \"many\", \"various\", \"well\", \"also\", \"however\",\n    \"several\", \"due\", \"across\", \"may\", \"without\", \"among\", \"including\", \"particular\",\n    \"especially\", \"either\", \"often\", \"even\", \"moreover\", \"thus\", \"ie\", \"eg\", \"although\",\n    \"despite\",\"would\" ,\"within\" ,\"\",\n]\n\nimport pandas as pd\ndef not_need(Text):\n    return \" \".join([word for word in Text.split() if word not in not_needed])\n\ntest_df['Text'] = test_df['Text'].apply(lambda x:not_need(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:25:05.129827Z","iopub.execute_input":"2024-02-09T18:25:05.130216Z","iopub.status.idle":"2024-02-09T18:25:06.293069Z","shell.execute_reply.started":"2024-02-09T18:25:05.130166Z","shell.execute_reply":"2024-02-09T18:25:06.29208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTTestDatasets(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.text = df.Text\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n        }\n\n# Create the test dataset\nresult_dataset = BERTTestDatasets(test_df, tokenizer, MAX_LEN)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:25:06.294598Z","iopub.execute_input":"2024-02-09T18:25:06.294936Z","iopub.status.idle":"2024-02-09T18:25:06.303522Z","shell.execute_reply.started":"2024-02-09T18:25:06.294909Z","shell.execute_reply":"2024-02-09T18:25:06.30262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_loader = DataLoader(result_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=4)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:25:06.306265Z","iopub.execute_input":"2024-02-09T18:25:06.306917Z","iopub.status.idle":"2024-02-09T18:25:06.325608Z","shell.execute_reply.started":"2024-02-09T18:25:06.306881Z","shell.execute_reply":"2024-02-09T18:25:06.324509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict():\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for _, data in enumerate(result_loader, 0):\n            ids = data['ids'].to(device, dtype=torch.long)\n            mask = data['mask'].to(device, dtype=torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n\n            outputs = model(ids, mask)\n            predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return predictions\n\n# Get predictions\ntest_predictions = predict()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:25:06.327259Z","iopub.execute_input":"2024-02-09T18:25:06.32799Z","iopub.status.idle":"2024-02-09T18:28:09.525325Z","shell.execute_reply.started":"2024-02-09T18:25:06.327956Z","shell.execute_reply":"2024-02-09T18:28:09.524247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Convert predictions to binary (True/False)\nbinary_predictions = np.array(test_predictions) >= 0.5\n\n# Convert boolean values to integers (1/0)\nbinary_predictions_int = binary_predictions.astype(int)\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame(binary_predictions_int, columns=target_cols)\nsubmission_df.insert(0, 'Id', test_df.Id)\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:28:09.526776Z","iopub.execute_input":"2024-02-09T18:28:09.527108Z","iopub.status.idle":"2024-02-09T18:28:09.789004Z","shell.execute_reply.started":"2024-02-09T18:28:09.527079Z","shell.execute_reply":"2024-02-09T18:28:09.788053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols2 = [col for col in df.columns if col not in ['Text','Title','Abstract']]\nlen(target_cols2)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:28:09.79036Z","iopub.execute_input":"2024-02-09T18:28:09.790716Z","iopub.status.idle":"2024-02-09T18:28:09.798101Z","shell.execute_reply.started":"2024-02-09T18:28:09.790684Z","shell.execute_reply":"2024-02-09T18:28:09.797096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Convert predictions to binary (True/False)\nbinary_predictions = np.array(test_predictions) >= 0.5\n\n# Convert boolean values to integers (1/0)\nbinary_predictions_int = binary_predictions.astype(int)\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame(binary_predictions_int, columns=target_cols2)\nsubmission_df.insert(0, 'Id', test_df.Id)\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:28:09.799556Z","iopub.execute_input":"2024-02-09T18:28:09.800201Z","iopub.status.idle":"2024-02-09T18:28:10.059279Z","shell.execute_reply.started":"2024-02-09T18:28:09.80015Z","shell.execute_reply":"2024-02-09T18:28:10.058372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template_df = pd.read_csv('/kaggle/input/kriti-csv/sample_submission.csv')\nrequired_column_order = template_df.columns.tolist()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:28:10.061688Z","iopub.execute_input":"2024-02-09T18:28:10.061985Z","iopub.status.idle":"2024-02-09T18:28:10.119383Z","shell.execute_reply.started":"2024-02-09T18:28:10.061961Z","shell.execute_reply":"2024-02-09T18:28:10.118478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensure that 'Id' is the first column\nrequired_column_order.remove('Id')\nrequired_column_order.insert(0, 'Id')\n\n# Reorder your DataFrame columns\nsubmission_df = submission_df[required_column_order]\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:28:10.120517Z","iopub.execute_input":"2024-02-09T18:28:10.120802Z","iopub.status.idle":"2024-02-09T18:28:10.128916Z","shell.execute_reply.started":"2024-02-09T18:28:10.120778Z","shell.execute_reply":"2024-02-09T18:28:10.127516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df\nsubmission_df.to_csv('/kaggle/working/submission_ordered_wow.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:28:10.130161Z","iopub.execute_input":"2024-02-09T18:28:10.130452Z","iopub.status.idle":"2024-02-09T18:28:10.329112Z","shell.execute_reply.started":"2024-02-09T18:28:10.130418Z","shell.execute_reply":"2024-02-09T18:28:10.328223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2024-02-09T18:28:10.330113Z","iopub.execute_input":"2024-02-09T18:28:10.330411Z","iopub.status.idle":"2024-02-09T18:28:10.355987Z","shell.execute_reply.started":"2024-02-09T18:28:10.330388Z","shell.execute_reply":"2024-02-09T18:28:10.355133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
